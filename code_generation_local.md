# Phase B: Code Generation - Local Deployment Design Document

> **Goal**: Build a .NET system that performs the same business functions as the mainframe batch system, running entirely on local infrastructure.

> **Philosophy**: First output may be imperfect. The system is designed to improve iteratively during development until 95% accuracy is achieved.

---

## Table of Contents

1. [Scope](#1-scope)
2. [Inputs and Verification](#2-inputs-and-verification)
3. [Component Handling Strategy](#3-component-handling-strategy)
4. [Conversion Tool Design](#4-conversion-tool-design)
5. [Agent Design](#5-agent-design)
6. [Conversion Process](#6-conversion-process)
7. [The Improvement Loop](#7-the-improvement-loop)
8. [Technical Patterns](#8-technical-patterns)
9. [File Handling Patterns](#9-file-handling-patterns)
10. [Edge Cases and Special Handling](#10-edge-cases-and-special-handling)
11. [Test Strategy](#11-test-strategy)
12. [Risks and Mitigations](#12-risks-and-mitigations)
13. [Deliverables](#13-deliverables)
14. [Target .NET Architecture](#14-target-net-architecture)
15. [Sample Output Structure](#15-sample-output-structure)
16. [Environment Configuration](#16-environment-configuration)
17. [Getting Started](#17-getting-started)

---

## 1. Scope

### 1.1 In Scope

| Component | Target |
|-----------|--------|
| COBOL batch programs | C# services |
| Copybooks | C# entities |
| JCL batch jobs | Background workers + configuration |
| REXX scripts | C# or configuration |
| Sequential files (QSAM) | **Local file system** |
| VSAM files | **SQL Server LocalDB** |
| DB2 embedded SQL | EF Core (SQL Server LocalDB) |
| IBM batch utilities | C# code (generated by agent) |
| Third-party utilities | C# code or placeholders |
| Parmlib/Configuration | appsettings.json |
| Secrets/Credentials | .NET User Secrets / Environment Variables |

### 1.2 Out of Scope

| Component | Reason |
|-----------|--------|
| CICS online transactions | Different architecture |
| IMS DB/DC | Requires specialized migration |
| BMS maps (screens) | UI components |
| Complex assembler | Machine-specific |

### 1.3 Flagged for Human Review (During Development)

| Construct | Reason |
|-----------|--------|
| ALTER verb | Self-modifying code (see Section 9.2 for details) |
| Complex PERFORM THRU with GO TO | Risk of incorrect control flow |
| REDEFINES with ambiguous types | Multiple interpretations |
| Unknown utilities | Need research |

---

## 2. Inputs and Verification

### 2.1 Required Inputs

| Input | Source | Assumption |
|-------|--------|------------|
| Source files | Client | Complete and accessible |
| Phase A outputs | Phase A tool | **Assumed correct** |

### 2.2 Optional Inputs

| Input | Impact |
|-------|--------|
| Sample data + expected outputs | Enables behavioral verification |

### 2.3 Two Verification Scenarios

| Scenario | What We Verify | Our Commitment |
|----------|----------------|----------------|
| **With sample data** | Actual output matches expected | 95% of tests pass |
| **Without sample data** | Compilation and structure | 95% of components compile successfully |

---

## 3. Component Handling Strategy

### 3.1 Conversion Mapping

| Source | Target | Key Mapping |
|--------|--------|-------------|
| COBOL Program | C# Service + Interface | Paragraph → method, WORKING-STORAGE → instance fields |
| Copybook | C# Entity (POCO) | Fields → properties, 88-levels → enums |
| JCL Job | BackgroundService + Config | Steps → method calls, COND → if/else |
| REXX | C# or removed | Based on purpose analysis |

### 3.2 Local Storage Mapping

| Mainframe | Local Equivalent | Rationale |
|-----------|------------------|-----------|
| Sequential files (QSAM) | Local file system (`data/` folder) | Direct file I/O, maintains flat file semantics |
| VSAM KSDS | SQL Server LocalDB table with primary key | Key-sequenced access via EF Core |
| VSAM ESDS | SQL Server LocalDB table with auto-increment ID | Entry-sequenced via EF Core |
| VSAM RRDS | SQL Server LocalDB table with row number | Relative record access |
| DB2 | SQL Server LocalDB | Full SQL support via EF Core |

**Database Options:**

| Option | Use Case | Notes |
|--------|----------|-------|
| **SQL Server LocalDB** | Default for .NET development | Free, included with Visual Studio, production-compatible SQL |
| **SQL Server Express** | Multi-user local testing | Free, networked access, 10GB limit |

### 3.3 GDG (Generation Data Group) Handling

Mainframe GDGs provide automatic file versioning (e.g., `PAYROLL.DATA(0)` = current, `PAYROLL.DATA(-1)` = previous generation).

**Local Pattern: Directory-based versioning with JSON metadata**

> **Note:** We do NOT use symlinks because they require admin privileges on Windows. Instead, the `generations.json` file tracks which folder is the current generation, and the `IGdgService` resolves paths programmatically.

| GDG Reference | Resolution Method |
|---------------|-------------------|
| `dataset(0)` | Read `generations.json`, find entry with `gen: 0`, return path |
| `dataset(+1)` | Create new folder `gen_{timestamp}/`, update JSON with `gen: 0` |
| `dataset(-1)` | Read `generations.json`, find entry with `gen: -1`, return path |

**Implementation:**
```
data/
└── payroll/
    ├── gen_20260122_100000/              # Current generation (gen 0)
    │   └── payroll.dat
    ├── gen_20260121_100000/              # Previous generation (gen -1)
    │   └── payroll.dat
    ├── gen_20260120_100000/              # Older generation (gen -2)
    │   └── payroll.dat
    └── generations.json                   # Metadata - THIS is the source of truth
```

**generations.json structure:**
```json
{
  "dataset": "payroll",
  "maxGenerations": 10,
  "generations": [
    { "gen": 0, "path": "gen_20260122_100000", "created": "2026-01-22T10:00:00" },
    { "gen": -1, "path": "gen_20260121_100000", "created": "2026-01-21T10:00:00" },
    { "gen": -2, "path": "gen_20260120_100000", "created": "2026-01-20T10:00:00" }
  ]
}
```

**How generation rollover works:**
1. When creating `dataset(+1)`, create new folder with timestamp
2. Update `generations.json`: new folder becomes `gen: 0`, all others decrement (`0` → `-1`, `-1` → `-2`, etc.)
3. If `gen` exceeds `-maxGenerations`, delete that folder

**Agent responsibility:** When converting JCL that references GDGs, the agent generates code that uses the `IGdgService` interface to resolve generation references via JSON lookup.

### 3.4 Utility Handling (IBM and Third-Party)

**Same approach for all utilities** (IBM and third-party):

| Step | Action |
|------|--------|
| 1 | LLM attempts to identify and convert based on its knowledge |
| 2 | If unknown, lookup in `utility_mappings.json` |
| 3 | If still unknown, generate placeholder comment |
| 4 | Log to `unknown_utilities.md` for human research |

**utility_mappings.json structure:**

| Field | Purpose |
|-------|---------|
| `name` | Utility name (e.g., "SORT", "IDCAMS") |
| `description` | Brief explanation of what the utility does |
| `dotnet_equivalent` | .NET replacement (e.g., "LINQ OrderBy") |
| `notes` | Optional - any special handling |

**Logging unknown utilities to unknown_utilities.md:**

| Field | Purpose |
|-------|---------|
| Utility name | What was found |
| File where found | Source file path |
| Context | Surrounding code/parameters |

Human reviews `unknown_utilities.md` and either adds to `utility_mappings.json` or documents as gap.

---

## 4. Conversion Tool Design

### 4.1 Components

| Component | Purpose |
|-----------|---------|
| Agent | LangGraph-based, orchestrates conversion |
| Services | Load Phase A, run builds, track status |
| Prompts | Templates for each component type |

### 4.2 Knowledge Files

| File | Purpose | Maintained By |
|------|---------|---------------|
| `conversion_guide.md` | Patterns AND anti-patterns (together) | Human (during development) |
| `code_style_guide.md` | Naming conventions, code standards | Human (during development) |
| `utility_mappings.json` | IBM + third-party utility mappings | Human (during development) |

**Why patterns and anti-patterns in same file:**
- LLM benefits from seeing wrong vs right side-by-side
- "Don't do X, do Y instead" is more effective
- Related patterns retrieved together via RAG
- Simpler maintenance

### 4.3 Conversion Guide Structure

```
# Conversion Guide

## Pattern: COMP-3 Handling
**Situation**: Converting packed decimal fields
**Pattern**: Use decimal type with Math.Truncate for COBOL truncation behavior
**Anti-Pattern**: Don't use float/double (precision loss)
**Anti-Pattern**: Don't use Math.Round (COBOL truncates, doesn't round)

## Pattern: WORKING-STORAGE State
**Situation**: Converting program-level variables
**Pattern**: Use private instance fields
**Anti-Pattern**: Don't use local variables (state lost between method calls)
```

### 4.4 Code Style Guide

Separate file (`code_style_guide.md`) given to agent containing:

| Section | Content |
|---------|---------|
| Naming conventions | PascalCase, _camelCase, etc. |
| File structure | Namespace, usings order |
| Documentation | XML comments requirements |
| Comments | When to add comments, format |
| TODO format | How to mark uncertain sections |

---

## 5. Agent Design

### 5.1 Framework: LangGraph

**Why**: Explicit state management, graph-based control flow, built-in persistence.

### 5.2 Agent Autonomy

**Principle**: The agent is fully autonomous. We give it minimal starting information. The agent uses tools to load everything else it needs.

**What we provide to start the agent:**

| Input | Description |
|-------|-------------|
| Component name | e.g., "PAYROLL.cbl" |
| Component type | cobol, copybook, jcl, rexx |
| Source directory path | Where source files are located |
| Phase A output path | Where Phase A outputs are located |
| Output directory path | Where to write generated code |

**Everything else is loaded by the agent using tools.**

### 5.3 Agent State (Minimal)

The agent state only tracks progress, not content:

| State Field | Purpose |
|-------------|---------|
| Component name | Current component being processed |
| Component type | Type of component |
| Status | pending, in_progress, converted, failed |
| Retry count | How many build fix attempts |
| Current errors | Build errors for fix loop |

**Content is NOT stored in state.** Agent uses tools to load content when needed.

### 5.4 Agent Tools

The agent uses these tools to load context and perform actions:

**Loading Tools:**

| Tool | Input | Returns | Purpose |
|------|-------|---------|---------|
| `read_file(path)` | File path | File content | Generic file reader - works for source, Phase A, style guide, etc. |
| `search_guide(keywords)` | Keywords | Relevant patterns | RAG search on conversion_guide.md |
| `lookup_utility(name)` | Utility name | .NET equivalent or null | Search utility_mappings.json |
| `get_component_status(name)` | Component name | Status and output path | Check if dependency is converted |

**Action Tools:**

| Tool | Input | Purpose |
|------|-------|---------|
| `write_file(path, content)` | Path + content | Write generated code |
| `run_build(solution_path)` | Solution path | Execute `dotnet build`, return errors |
| `run_tests(solution_path)` | Solution path | Execute `dotnet test`, return results |
| `log_issue(file, type, description)` | Issue details | Append to issue_log.md |
| `log_unknown_utility(name, file, context)` | Utility details | Append to unknown_utilities.md |
| `update_status(component, status)` | Status details | Update conversion_status.md |

### 5.5 Agent Flow

```
┌─────────────────────────────────────────────────────────────────────────┐
│ START: Agent receives component name, type, and directory paths          │
└─────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────┐
│ LOAD CONTEXT NODE                                                        │
│ Agent uses tools:                                                        │
│   1. read_file(source_path) → gets source code                           │
│   2. read_file(phase_a_path) → gets Phase A summary                      │
│   3. read_file(style_guide_path) → gets code standards                   │
│   4. search_guide(keywords from source) → gets relevant patterns         │
└─────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────┐
│ GENERATE CODE NODE                                                       │
│ LLM generates C# code based on loaded context                            │
│ If LLM encounters unknown utility:                                       │
│   → lookup_utility(name) to find .NET equivalent                         │
│   → if not found, log_unknown_utility(name, context)                     │
└─────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────┐
│ WRITE FILES NODE                                                         │
│ Agent uses: write_file(path, content)                                    │
└─────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────┐
│ BUILD NODE                                                               │
│ Agent uses: run_build()                                                  │
│   → Returns success or list of errors                                    │
└─────────────────────────────────────────────────────────────────────────┘
                                    │
                    ┌───────────────┼───────────────┐
                    ▼               ▼               ▼
                 Success      Retry (≤3)        Give Up
                    │               │               │
                    ▼               ▼               ▼
               run_tests      fix_errors     log_issue
                    │               │               │
                    ▼               │               ▼
             update_status          └──→ WRITE FILES (loop)
                    │                               │
                    ▼                               ▼
                  END                        update_status
                                                    │
                                                    ▼
                                                  END
```

### 5.6 How Agent Finds Relevant Patterns

When agent calls `search_guide(keywords)`:

| Step | Action |
|------|--------|
| 1 | Agent extracts keywords from source (e.g., "COMP-3", "PERFORM THRU") |
| 2 | Tool searches conversion_guide.md using semantic search (RAG) |
| 3 | Returns most relevant patterns to agent |
| 4 | Agent uses these patterns when generating code |

This ensures agent gets only relevant patterns, not the entire guide (saves context window).

---

## 6. Conversion Process

### 6.1 Processing Order

**Sequential processing in dependency order:**

| Order | Type | Reason |
|-------|------|--------|
| 1 | Copybooks | No dependencies |
| 2 | Utility programs | Depend on copybooks |
| 3 | Subroutines | Depend on utilities |
| 4 | Main programs | Depend on subroutines |
| 5 | JCL jobs | Orchestrate programs |

Components are processed one at a time. Each must complete before the next starts.

### 6.2 Per-Component Flow (What Agent Does)

The agent is invoked for each component:

| Step | Agent Action | Tool Used |
|------|--------------|-----------|
| 1 | Load source code | `read_file(source_path)` |
| 2 | Load Phase A summary | `read_file(phase_a_path)` |
| 3 | Load code style guide | `read_file(style_guide_path)` |
| 4 | Find relevant conversion patterns | `search_guide(keywords)` |
| 5 | If depends on other programs, check status | `get_component_status(name)` |
| 6 | Generate C# code | (LLM reasoning) |
| 7 | If unknown utility in code, look it up | `lookup_utility(name)` |
| 8 | If utility still unknown, log it | `log_unknown_utility(name, context)` |
| 9 | Write generated code to file | `write_file(path, content)` |
| 10 | Run build | `run_build()` |
| 11 | If build fails and retries < 3, fix and retry | Back to step 6 with error context |
| 12 | If build fails after 3 retries, log issue | `log_issue(...)` |
| 13 | If build succeeds, run tests | `run_tests()` |
| 14 | Update status | `update_status(component, status)` |

---

## 7. The Improvement Loop

> **Key Principle**: Human review happens only during development to improve the tool. In production, the tool runs without human intervention.

### 7.1 Development Phase Iterations

| Iteration | Input | Output | Human Action |
|-----------|-------|--------|--------------|
| **Run 1** | Initial guide + source | Baseline conversion | Review failures, update guide |
| **Run 2** | Updated guide | Improved conversion | Review remaining failures, update guide |
| **Run 3** | Final guide | Target conversion | Accept remaining as documented gaps |

### 7.2 After Each Run

| Step | Who | Action |
|------|-----|--------|
| 1 | Tool | Generate `issue_log.md` with all failures |
| 2 | Tool | Generate `unknown_utilities.md` with unknown utilities |
| 3 | Human | Review failures, identify patterns |
| 4 | Human | Update `conversion_guide.md` with new patterns |
| 5 | Human | Add unknown utilities to `utility_mappings.json` |
| 6 | Tool | Re-run failed components only |

### 7.3 Iteration Exit Criteria

| Condition | Action |
|-----------|--------|
| 95% accuracy achieved | ✅ Done - proceed to production |
| 3 iterations completed, <95% | Stop - remaining are documented gaps |
| No improvement between runs | Stop - current accuracy is ceiling |

### 7.4 Production Phase

**No human intervention**. The tool runs with finalized knowledge files.
New projects benefit from all learnings from previous projects.

---

## 8. Technical Patterns

### 8.1 State Management

| COBOL | C# | Rationale |
|-------|-----|-----------|
| WORKING-STORAGE | Instance fields | State persists within job |
| LOCAL-STORAGE | Local variables | State per method |
| Program lifetime | Scoped service | One instance per job |

### 8.2 Control Flow

| COBOL | C# |
|-------|-----|
| PERFORM | Method call |
| PERFORM THRU | Wrapper method |
| GO TO DEPENDING ON | Switch statement |
| ALTER | **Gap** (see Section 9.2) |

### 8.3 Data Types

| COBOL | C# |
|-------|-----|
| PIC 9(n) | int/long |
| PIC 9(n)V9(m) | decimal |
| PIC X(n) | string |
| COMP-3 | decimal |
| 88-level | enum |
| OCCURS | List or array |

### 8.4 Decimal Handling

COBOL truncates by default. C# preserves precision.

**Pattern**: Use `Math.Truncate()` where COBOL would truncate.

### 8.5 Local File I/O Patterns

| COBOL Operation | C# Local Equivalent |
|-----------------|---------------------|
| OPEN INPUT | `File.OpenRead()` or `StreamReader` |
| OPEN OUTPUT | `File.Create()` or `StreamWriter` |
| OPEN EXTEND | `File.AppendText()` |
| READ | `reader.ReadLine()` or fixed-length read |
| WRITE | `writer.WriteLine()` or fixed-length write |
| CLOSE | `Dispose()` via `using` statement |

**Fixed-length records pattern:**
```csharp
// Read fixed-length record (80 bytes)
byte[] buffer = new byte[80];
stream.Read(buffer, 0, 80);
string record = Encoding.ASCII.GetString(buffer);

// Write fixed-length record
string paddedRecord = record.PadRight(80);
byte[] bytes = Encoding.ASCII.GetBytes(paddedRecord);
stream.Write(bytes, 0, 80);
```

---

## 9. File Handling Patterns

### 9.1 Record Types

| Record Type | Mainframe | Local .NET Pattern |
|-------------|-----------|-------------------|
| Fixed-length | FB (Fixed Block) | Read/write exact byte count |
| Variable-length | VB (Variable Block) | Read RDW (Record Descriptor Word) first, then data |
| Spanned | VBS | Assemble segments before processing |

**Fixed-Length Records:**
- Record length defined in copybook (e.g., 80 bytes)
- Read/write exact byte count using binary streams
- Pad strings to field length on write

**Variable-Length Records:**
- First 4 bytes = RDW (2-byte length + 2-byte reserved)
- Read RDW to get record length, then read that many bytes
- Agent generates code to handle RDW parsing

### 9.2 VSAM File Patterns

| VSAM Type | SQL Server Equivalent | Access Pattern |
|-----------|----------------------|----------------|
| **KSDS** | Table with primary key | Key lookup, sequential, skip-sequential |
| **ESDS** | Table with identity column | Sequential only, append |
| **RRDS** | Table with row number | Direct by relative record number |

**VSAM Alternate Indexes:**

Mainframe VSAM KSDS files can have alternate indexes for secondary key access.

| Mainframe | SQL Server Equivalent |
|-----------|----------------------|
| Primary key | `PRIMARY KEY` constraint |
| Alternate index (unique) | `UNIQUE INDEX` |
| Alternate index (non-unique) | Standard `INDEX` |

Agent generates EF Core entity with appropriate index attributes based on Phase A analysis of VSAM definitions.

### 9.3 DD Statement / SYSIN Handling

JCL DD statements define file assignments and inline data. These are converted to:

| JCL Concept | Local .NET Equivalent |
|-------------|----------------------|
| DD with DSN | File path in appsettings.json |
| DD with * (inline SYSIN) | Embedded resource or separate config file |
| DD DUMMY | Null object pattern (discard writes, return EOF on read) |
| PARM= | Command-line arguments or appsettings |

**File path configuration pattern:**
```
appsettings.json:
{
  "FileAssignments": {
    "CUSTFILE": "data/input/customers.dat",
    "TRANFILE": "data/input/transactions.dat",
    "RPTFILE": "data/output/report.txt"
  }
}
```

### 9.4 Checkpoint/Restart (Long-Running Jobs)

Mainframe batch jobs use checkpoint/restart to recover from failures in long-running processes.

| Mainframe Concept | Local .NET Pattern |
|-------------------|-------------------|
| CHECKPOINT statement | Save progress to checkpoint file/table |
| RESTART from checkpoint | Read last checkpoint, resume from that point |
| Commit interval | Process N records, then checkpoint |

**Local checkpoint pattern:**
- Store checkpoint data in `data/checkpoints/{job}_{date}.json`
- Contains: last processed record ID, step name, timestamp
- On restart, read checkpoint and skip already-processed records
- Agent flags long-running loops for checkpoint consideration

### 9.5 File Status and Error Handling

| COBOL FILE STATUS | Meaning | C# Handling |
|-------------------|---------|-------------|
| 00 | Success | Continue |
| 10 | End of file | Return from read loop |
| 23 | Record not found (VSAM) | Throw `KeyNotFoundException` or return null |
| 35 | File not found | Throw `FileNotFoundException` |
| 39 | File attribute mismatch | Throw `InvalidOperationException` |
| 9x | I/O error | Throw `IOException` with details |

Agent generates try-catch blocks that map FILE STATUS codes to appropriate .NET exceptions.

---

## 10. Edge Cases and Special Handling

### 10.1 Known Edge Cases

| Case | Handling |
|------|----------|
| **EBCDIC encoding** | Assume client provides ASCII |
| **Julian dates** | Pattern: Parse with DateTime |
| **Fixed-length records** | Pattern: Parse by positions from copybook |
| **Signed COMP-3** | Pattern: Check high nibble for sign |
| **REDEFINES** | Generate separate class, flag for review |

### 10.2 Why ALTER is Not Converted

**What ALTER does:**
ALTER changes the target of a GO TO statement at runtime. It's self-modifying code.

**Example:**
```
ALTER PARA-A TO PROCEED TO PARA-B.
...
PARA-A.
    GO TO PARA-UNKNOWN.   * Target changed by ALTER above
```

**Why it can't be converted:**
1. C# does not support self-modifying code
2. No equivalent pattern exists
3. The control flow is unpredictable without runtime analysis
4. It's considered harmful even in COBOL (rarely used in modern code)

**Handling:**
- Flag for human review during development
- Human must analyze the intent and rewrite the logic
- Document as a known gap

### 10.3 Constructs We Always Flag

| Construct | Reason |
|-----------|--------|
| ALTER | Self-modifying code |
| Complex GO TO networks | Unstructured control flow |
| EXEC CICS | Out of scope |
| Inline assembler | Machine-specific |

---

## 11. Test Strategy

### 11.1 With Sample Data

- Generate tests that assert actual output = expected output
- These are **ground truth tests**
- Failures indicate conversion errors

### 11.2 Without Sample Data

- Generate tests that verify methods exist
- Verify basic execution without exceptions
- These are **structural tests only**
- Passing does NOT guarantee correctness

### 11.3 Coverage Goal

- Every Phase A functionality has a corresponding test
- Every service has at least one test

### 11.4 Local Test Execution

| Tool | Purpose |
|------|---------|
| `dotnet test` | Run all unit tests |
| xUnit/NUnit | Test framework |
| SQL Server LocalDB | Database integration tests |
| Temporary directories | Isolated file I/O tests |

---

### 11.5 Logging and Observability

**Local logging uses Serilog** with file and console sinks (vs Application Insights in Azure).

| Component | Implementation |
|-----------|----------------|
| Structured logging | Serilog with JSON formatting |
| Console output | Serilog.Sinks.Console |
| File logging | Serilog.Sinks.File (rolling daily) |
| Log viewer (optional) | Seq (free for local use) |

**Log configuration (appsettings.json):**
```json
{
  "Serilog": {
    "MinimumLevel": "Information",
    "WriteTo": [
      { "Name": "Console" },
      {
        "Name": "File",
        "Args": {
          "path": "logs/job-.log",
          "rollingInterval": "Day"
        }
      }
    ],
    "Enrich": ["FromLogContext"]
  }
}
```

**Job execution tracing:**

| Field | Purpose |
|-------|--------|
| `JobId` | Unique identifier for job run |
| `StepName` | Current JCL step being executed |
| `ComponentName` | COBOL program or service name |
| `CorrelationId` | Links related log entries |

**Example log output:**
```
2026-01-22 10:00:00 [INF] Job DAILY_PAYROLL started {JobId: "job_123", CorrelationId: "abc-def"}
2026-01-22 10:00:01 [INF] Step STEP010 executing {JobId: "job_123", StepName: "STEP010", Service: "PayrollValidationService"}
2026-01-22 10:00:05 [INF] Step STEP010 completed {JobId: "job_123", StepName: "STEP010", ReturnCode: 0, Duration: "4.2s"}
```

---

## 12. Risks and Mitigations

| Risk | Impact | Mitigation |
|------|--------|------------|
| LLM produces incorrect logic | High | Sample data verification, iteration loop |
| Unknown utilities block progress | Medium | Log and continue, human researches async |
| Context window exceeded | Medium | On-demand loading, chunking for large files |
| 95% not achievable | High | After 3 iterations, remaining = documented gaps |
| Generated code unmaintainable | Medium | Code style guide, patterns in conversion guide |
| Inconsistent output | Medium | Centralized patterns and style guide |
| Local storage performance issues | Low | SQL Server LocalDB handles typical batch volumes |

---

## 13. Deliverables

### 13.1 Generated Solution

| Folder | Content |
|--------|---------|
| `src/Core/Entities` | C# POCOs from copybooks |
| `src/Core/Services` | C# services from COBOL programs |
| `src/Core/Enums` | Enums from 88-level conditions |
| `src/Worker/Jobs` | Console apps from JCL steps |
| `src/Infrastructure/Storage` | File and GDG service implementations |
| `src/Infrastructure/Data` | EF Core DbContext for VSAM and DB2 |
| `scripts/jobs` | PowerShell scripts from JCL jobs |
| `tests/` | Generated unit and integration tests |
| `data/` | Runtime data directories (input, output, checkpoints) |

### 13.2 Documentation

| File | Content |
|------|---------|
| `conversion_status.md` | Per-component status |
| `conversion_failures.md` | Failed components with reasons |
| `unknown_utilities.md` | Utilities that needed research |
| `gaps.md` | What wasn't converted and why |

---

## 14. Target .NET Architecture

### 14.1 Solution Layers

| Layer | Responsibility |
|-------|----------------|
| Core | Business logic (no external dependencies) |
| Worker | Background services (one per JCL job) |
| Infrastructure | Local file I/O, SQL Server, EF Core |

### 14.2 Key Design Decisions

| Decision | Rationale |
|----------|-----------|
| **Scoped services** | Match COBOL program lifetime |
| **Interface-based** | Enables testing and DI |
| **File system abstraction** | `IFileStorage` interface for testability |
| **Configuration-driven** | JCL parameters → appsettings.json |

### 14.3 Local Storage Implementation

**File Storage Interface:**
```csharp
public interface IFileStorage
{
    Stream OpenRead(string path);
    Stream OpenWrite(string path);
    Stream OpenAppend(string path);
    bool Exists(string path);
    void Delete(string path);
    IEnumerable<string> List(string directory);
}

public class LocalFileStorage : IFileStorage
{
    private readonly string _basePath;
    
    public LocalFileStorage(string basePath)
    {
        _basePath = basePath;
    }
    
    public Stream OpenRead(string path) 
        => File.OpenRead(Path.Combine(_basePath, path));
    
    // ... other implementations
}
```

**VSAM Replacement with SQL Server LocalDB:**
```csharp
public class VsamDbContext : DbContext
{
    // KSDS equivalent - keyed access
    public DbSet<CustomerRecord> Customers { get; set; }
    
    // ESDS equivalent - sequential access
    public DbSet<TransactionLog> Transactions { get; set; }
    
    protected override void OnConfiguring(DbContextOptionsBuilder options)
        => options.UseSqlServer(@"Server=(localdb)\mssqllocaldb;Database=VsamData;Trusted_Connection=True;");
}
```

**GDG Service Interface:**
```csharp
public interface IGdgService
{
    string ResolveGeneration(string datasetName, int relativeGen); // 0 = current, -1 = previous, +1 = new
    string CreateNewGeneration(string datasetName);
    void PruneOldGenerations(string datasetName, int keepCount);
}

public class LocalGdgService : IGdgService
{
    private readonly string _basePath;
    
    public string ResolveGeneration(string datasetName, int relativeGen)
    {
        var metadata = LoadMetadata(datasetName);
        var gen = metadata.Generations.FirstOrDefault(g => g.Gen == relativeGen);
        return gen?.Path ?? throw new FileNotFoundException($"Generation {relativeGen} not found");
    }
    
    public string CreateNewGeneration(string datasetName)
    {
        var newPath = $"gen_{DateTime.UtcNow:yyyyMMdd_HHmmss}";
        // Create directory, update metadata, update 'current' symlink
        return newPath;
    }
}
```

### 14.4 Job Orchestration with PowerShell Scripts

**JCL jobs are converted to two outputs:**
1. **Worker code** (C# Console Apps) - the job step logic
2. **PowerShell script** - orchestrates the steps with conditions

**Why PowerShell scripts:**
- JCL IS a script - PowerShell mirrors this perfectly
- Zero infrastructure - no database, no dashboard, no packages
- Easy to debug - add logging, skip steps, modify on the fly
- Native scheduling - Windows Task Scheduler handles it
- Everyone understands it

**Generated Script Structure (`scripts/jobs/`):**

```powershell
# run-daily-payroll.ps1
param(
    [string]$DataDate = (Get-Date -Format "yyyyMMdd"),
    [string]$DataDir = "./data"
)

$ErrorActionPreference = "Stop"
$JobName = "DAILY_PAYROLL"
$StartTime = Get-Date

Write-Host "=== Starting $JobName - Date: $DataDate ==="

# STEP010 - Validation
Write-Host "[STEP010] Running PayrollValidation..."
$step010 = & dotnet run --project src/Worker/Jobs/PayrollValidation -- --date $DataDate --data-dir $DataDir
$rc010 = $LASTEXITCODE
Write-Host "[STEP010] Completed with RC=$rc010"

if ($rc010 -ne 0) {
    Write-Error "[STEP010] Failed - aborting job"
    exit $rc010
}

# STEP020 - Calculation (COND=(4,LT) - run if STEP010 RC < 4)
Write-Host "[STEP020] Running PayrollCalculation..."
$step020 = & dotnet run --project src/Worker/Jobs/PayrollCalculation -- --date $DataDate --data-dir $DataDir
$rc020 = $LASTEXITCODE
Write-Host "[STEP020] Completed with RC=$rc020"

if ($rc020 -gt 4) {
    Write-Error "[STEP020] Failed with RC=$rc020 - aborting job"
    exit $rc020
}

# STEP030 - Report Generation
Write-Host "[STEP030] Running PayrollReport..."
$step030 = & dotnet run --project src/Worker/Jobs/PayrollReport -- --date $DataDate --data-dir $DataDir
$rc030 = $LASTEXITCODE
Write-Host "[STEP030] Completed with RC=$rc030"

# Job Summary
$Duration = (Get-Date) - $StartTime
Write-Host "=== $JobName completed in $($Duration.TotalSeconds)s - Final RC=$rc030 ==="
exit $rc030
```

**Return Code Semantics (matching JCL conventions):**

| Return Code | Meaning |
|-------------|--------|
| 0 | Success |
| 4 | Warning (continue) |
| 8 | Error (may abort) |
| 12+ | Severe error (abort) |

**Scheduling:**
- **Windows**: Task Scheduler → runs `powershell.exe -File scripts/jobs/run-daily-payroll.ps1`
- **Linux**: cron → runs `pwsh scripts/jobs/run-daily-payroll.ps1`

### 14.5 Architecture Diagram

```
┌─────────────────────────────────────────────────────────────────┐
│                   PowerShell Job Script                          │
│              (scripts/jobs/run-daily-payroll.ps1)                │
└─────────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│                     Console App Workers                          │
│              (One per JCL step, called by script)                 │
└─────────────────────────────────────────────────────────────────┘
                              │
            ┌─────────────────┼─────────────────┐
            ▼                 ▼                 ▼
┌───────────────────┐ ┌───────────────────┐ ┌───────────────────┐
│   Core Services   │ │   Core Services   │ │   Core Services   │
│ (Business Logic)  │ │ (Business Logic)  │ │ (Business Logic)  │
└───────────────────┘ └───────────────────┘ └───────────────────┘
            │                 │                 │
            └─────────────────┼─────────────────┘
                              │
            ┌─────────────────┼─────────────────┐
            ▼                 ▼                 ▼
┌───────────────────┐ ┌───────────────────┐ ┌───────────────────┐
│  Local Files      │ │  SQL Server       │ │  SQL Server       │
│  (data/*.dat)     │ │  (VSAM data)      │ │  (DB2 data)       │
└───────────────────┘ └───────────────────┘ └───────────────────┘
```

---

## 15. Sample Output Structure

This is what the generated solution looks like after conversion:

```
converted-solution/
│
├── ConvertedBatch.sln                         # .NET Solution file
│
├── src/
│   ├── Core/
│   │   ├── Core.csproj
│   │   │
│   │   ├── Entities/                          # From Copybooks
│   │   │   ├── CustomerRecord.cs              # ← CUSTOMER.cpy
│   │   │   ├── TransactionRecord.cs           # ← TRANSACT.cpy
│   │   │   ├── PayrollInput.cs                # ← PAYROLL-INPUT.cpy
│   │   │   └── PayrollOutput.cs               # ← PAYROLL-OUTPUT.cpy
│   │   │
│   │   ├── Services/                          # From COBOL Programs
│   │   │   ├── IPayrollValidationService.cs
│   │   │   ├── PayrollValidationService.cs    # ← PAYVAL.cbl
│   │   │   ├── IPayrollCalculationService.cs
│   │   │   ├── PayrollCalculationService.cs   # ← PAYCALC.cbl
│   │   │   ├── ICustomerLookupService.cs
│   │   │   └── CustomerLookupService.cs       # ← CUSTLKUP.cbl
│   │   │
│   │   └── Enums/                             # From 88-levels
│   │       ├── TransactionType.cs
│   │       └── CustomerStatus.cs
│   │
│   ├── Infrastructure/
│   │   ├── Infrastructure.csproj
│   │   │
│   │   ├── Data/
│   │   │   ├── VsamDbContext.cs               # VSAM tables
│   │   │   └── AppDbContext.cs                # DB2 tables
│   │   │
│   │   ├── Storage/
│   │   │   ├── IFileStorage.cs
│   │   │   ├── LocalFileStorage.cs
│   │   │   ├── IGdgService.cs
│   │   │   └── LocalGdgService.cs
│   │   │
│   │   └── DependencyInjection.cs             # Service registration
│   │
│   └── Worker/
│       └── Jobs/                              # From JCL Steps
│           ├── PayrollValidation/
│           │   ├── PayrollValidation.csproj   # Console app
│           │   └── Program.cs
│           │
│           ├── PayrollCalculation/
│           │   ├── PayrollCalculation.csproj
│           │   └── Program.cs
│           │
│           └── PayrollReport/
│               ├── PayrollReport.csproj
│               └── Program.cs
│
├── scripts/
│   └── jobs/                                  # From JCL Jobs
│       ├── run-daily-payroll.ps1              # ← DAILY_PAYROLL JCL
│       ├── run-month-end.ps1                  # ← MONTH_END JCL
│       └── run-customer-extract.ps1           # ← CUST_EXTRACT JCL
│
├── data/                                      # Runtime data
│   ├── input/
│   │   ├── customers.dat
│   │   └── transactions.dat
│   │
│   ├── output/
│   │   └── reports/
│   │
│   ├── payroll/                               # GDG example
│   │   ├── gen_20260122_100000/               # Current (gen 0)
│   │   │   └── payroll.dat
│   │   ├── gen_20260121_100000/               # Previous (gen -1)
│   │   │   └── payroll.dat
│   │   └── generations.json                   # Tracks current generation
│   │
│   └── checkpoints/                           # Job checkpoints
│       └── daily_payroll_20260122.json
│
├── tests/
│   ├── Core.Tests/
│   │   ├── Core.Tests.csproj
│   │   ├── PayrollValidationServiceTests.cs
│   │   └── CustomerLookupServiceTests.cs
│   │
│   └── Integration.Tests/
│       ├── Integration.Tests.csproj
│       └── EndToEndJobTests.cs
│
├── docs/
│   ├── conversion_status.md                   # Per-component status
│   ├── conversion_failures.md                 # Failed components
│   ├── unknown_utilities.md                   # Utilities needing research
│   └── gaps.md                                # Documented gaps
│
├── appsettings.json                           # Default configuration
├── appsettings.Development.json               # Dev overrides
├── appsettings.Test.json                      # Test overrides
│
├── logs/                                      # Runtime logs
│   └── job-20260122.log
│
└── README.md                                  # How to run
```

### 15.1 Project Dependencies

| Project | References | NuGet Packages |
|---------|------------|----------------|
| **Core** | None | (none - pure business logic) |
| **Infrastructure** | Core | `Microsoft.EntityFrameworkCore.SqlServer`, `Serilog` |
| **Worker/Jobs/**** | Core, Infrastructure | `Microsoft.Extensions.Hosting`, `Serilog.Sinks.Console`, `Serilog.Sinks.File` |
| **Tests** | Core, Infrastructure | `xunit`, `Moq`, `FluentAssertions` |

### 15.2 What Each Component Contains

| Folder | Contents | Generated From |
|--------|----------|----------------|
| `Entities/` | POCOs with properties matching copybook fields | Copybooks |
| `Services/` | Interface + implementation per COBOL program | COBOL programs |
| `Enums/` | Enums for 88-level conditions | COBOL 88-levels |
| `Worker/Jobs/` | Console apps that invoke services | JCL steps |
| `scripts/jobs/` | PowerShell scripts orchestrating console apps | JCL jobs |
| `data/` | Input/output files, GDG folders, checkpoints | Runtime data |

---

## 16. Environment Configuration

### 16.1 Configuration Files

| File | Purpose |
|------|---------|
| `appsettings.json` | Default/production configuration |
| `appsettings.Development.json` | Local development overrides |
| `appsettings.Test.json` | Test environment overrides |

### 16.2 Configuration Structure

```json
{
  "ConnectionStrings": {
    "VsamDb": "Server=(localdb)\\mssqllocaldb;Database=VsamData;Trusted_Connection=True;",
    "AppDb": "Server=(localdb)\\mssqllocaldb;Database=AppData;Trusted_Connection=True;"
  },
  
  "FileAssignments": {
    "CUSTFILE": "data/input/customers.dat",
    "TRANFILE": "data/input/transactions.dat",
    "RPTFILE": "data/output/reports/daily_report.txt"
  },
  
  "GdgSettings": {
    "BasePath": "data",
    "MaxGenerations": 10
  },
  
  "JobSettings": {
    "CheckpointEnabled": true,
    "CheckpointPath": "data/checkpoints",
    "CommitInterval": 1000
  },
  
  "Serilog": {
    "MinimumLevel": "Information",
    "WriteTo": [
      { "Name": "Console" },
      { "Name": "File", "Args": { "path": "logs/job-.log", "rollingInterval": "Day" } }
    ]
  }
}
```

### 16.3 Secrets Management

| Environment | Method |
|-------------|--------|
| **Development** | .NET User Secrets (`dotnet user-secrets set`) |
| **Test/CI** | Environment variables |
| **Production (Azure)** | Azure Key Vault |

---

## 17. Getting Started

### 17.1 Prerequisites

| Requirement | Version | Notes |
|-------------|---------|-------|
| .NET SDK | 8.0+ | `dotnet --version` to check |
| SQL Server LocalDB | 2019+ | Included with Visual Studio |
| PowerShell | 5.1+ (Windows) or PowerShell Core 7+ | For running job scripts |

### 17.2 Initial Setup

**Step 1: Restore packages**
```
cd converted-solution
dotnet restore
```

**Step 2: Create databases**
```
dotnet ef database update --project src/Infrastructure --context VsamDbContext
dotnet ef database update --project src/Infrastructure --context AppDbContext
```

**Step 3: Build solution**
```
dotnet build
```

### 17.3 Running Jobs

**Option 1: Run individual step**
```
dotnet run --project src/Worker/Jobs/PayrollValidation -- --date 20260122 --data-dir ./data
```

**Option 2: Run complete job via script**
```
.\scripts\jobs\run-daily-payroll.ps1 -DataDate "20260122"
```

**Option 3: Schedule job**
- Open Windows Task Scheduler
- Create task → Action: `powershell.exe -File scripts\jobs\run-daily-payroll.ps1`
- Set trigger (daily at 2:00 AM)

### 17.4 Running Tests

```
dotnet test
```

### 17.5 Viewing Logs

Logs are written to `logs/` folder with daily rotation:
- `logs/job-20260122.log` - All job execution logs

Optional: Install Seq for log viewing:
```
docker run -d --name seq -e ACCEPT_EULA=Y -p 5341:80 datalust/seq
```
Then add Seq sink to Serilog configuration.

---

## Summary

### Complete Mainframe to Local Mapping

| Mainframe Component | Local .NET Replacement |
|---------------------|------------------------|
| **COBOL Programs** | C# Services |
| **Copybooks** | C# Entities (POCOs) |
| **JCL Jobs (logic)** | C# Console Apps |
| **JCL Jobs (orchestration)** | PowerShell scripts + Windows Task Scheduler |
| **JCL Scheduling** | Windows Task Scheduler (or cron on Linux) |
| **REXX Scripts** | C# code or configuration |
| **Sequential Files (QSAM)** | Local file system (`data/` folder) |
| **VSAM (KSDS/ESDS/RRDS)** | SQL Server LocalDB tables |
| **GDG (Generation Data Groups)** | Directory-based versioning + `generations.json` |
| **DB2** | SQL Server LocalDB via EF Core |
| **IBM Utilities (SORT, IDCAMS, etc.)** | C# code generated by agent |
| **Third-party Utilities** | C# code or placeholders |
| **Parmlib / Configuration** | appsettings.json |
| **Secrets / Credentials** | .NET User Secrets / Environment Variables |
| **Logging / SMF Records** | Serilog (file + console sinks) |
| **Checkpoint/Restart** | JSON checkpoint files |

### Key Differences from Azure Version

| Aspect | Azure Version | Local Version |
|--------|---------------|---------------|
| Sequential files | Azure Blob Storage | Local file system |
| VSAM files | Azure Table Storage | SQL Server LocalDB |
| Job orchestration | Azure Logic Apps | PowerShell scripts |
| Workers | Azure Container Apps/Functions | Console apps |
| Configuration output | Bicep/Logic Apps JSON | PowerShell scripts |
| Secrets | Azure Key Vault | User Secrets / Environment Variables |
| Logging | Application Insights | Serilog |

### The Approach

1. **First run will be imperfect** - this is expected
2. **Systematic improvement** - analyze failures, update guides, re-run
3. **Human effort during development only** - improving the tool
4. **Production is automated** - no human intervention needed

### Key Files

| File | Purpose |
|------|---------|
| `conversion_guide.md` | Patterns + anti-patterns (together) |
| `code_style_guide.md` | Naming and code standards |
| `utility_mappings.json` | IBM + third-party utility mappings |
| `unknown_utilities.md` | For human research |
| `scripts/jobs/*.ps1` | PowerShell job scripts (from JCL) |

### Definition of Done

- 95% of components meet criteria
- Remaining are documented gaps
- Tool is ready for production use on new projects

